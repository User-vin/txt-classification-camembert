{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import data\n",
    "import os\n",
    "\n",
    "from transformers import TFAutoModel\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import (\n",
    "    Concatenate,\n",
    "    Conv1D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    # Embedding,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    MaxPooling1D,\n",
    ")\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import \n",
    "import os\n",
    "import config\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import TFCamembertModel\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    confusion_matrix, \n",
    "    ConfusionMatrixDisplay,\n",
    "    f1_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    roc_curve,\n",
    "    roc_auc_score \n",
    ")\n",
    "\n",
    "\n",
    "def calculate_estimated_year_tensor(intervals, probabilities):\n",
    "    def get_bounds(interval: str):\n",
    "        start, end = interval.strip(\"[]()\").split(\", \")\n",
    "        return int(start), int(end)\n",
    "    \n",
    "    values = []\n",
    "    for i, interval in enumerate(intervals):\n",
    "        start, end = get_bounds(interval)\n",
    "        if i == 0:\n",
    "            values.append(start)\n",
    "        elif i == len(intervals) - 1:\n",
    "            values.append(end)\n",
    "        else:\n",
    "            values.append((start + end) / 2)\n",
    "    \n",
    "    values_tensor = tf.constant(values, dtype=tf.float32)\n",
    "    estimated_date = tf.reduce_sum(values_tensor * probabilities, axis=1)\n",
    "    estimated_year = tf.round(estimated_date)\n",
    "    \n",
    "    return estimated_year\n",
    "\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    # Obtenez les années estimées en utilisant les prédictions fournies par le modèle\n",
    "    # intervals = ['[1825, 1850)', '[1850, 1875)', '[1875, 1900)', '[1900, 1925)', '[1925, 1950)', '[1950, 1975)', '[1975, 2000)', '[2000, 2024)']\n",
    "    estimated_years = calculate_estimated_year_tensor(list(config.DATE_MAP.values()), y_pred)\n",
    "    # estimated_years = calculate_estimated_year_tensor(intervals, y_pred)\n",
    "    # Convertir y_true en float32 sans changer la shape\n",
    "    y_true_float = tf.cast(y_true, tf.float32)\n",
    "    # Reshape y_true_float : passer de [16 1] à [16]\n",
    "    y_true_float = tf.reshape(y_true_float, [-1])\n",
    "    # Calculez les erreurs carrées entre les années estimées et les valeurs réelles\n",
    "    squared_errors = tf.square(estimated_years - y_true_float)\n",
    "    # Sommez les carrés des erreurs pour obtenir la somme totale des erreurs\n",
    "    sum_of_squared_errors = tf.reduce_sum(squared_errors)\n",
    "    # Calculer le nombre total d'échantillons\n",
    "    num_samples = tf.cast(tf.shape(y_true_float)[0], tf.float32)\n",
    "    # Calculer la moyenne des erreurs carrées\n",
    "    mean_squared_error = sum_of_squared_errors / num_samples\n",
    "    \n",
    "    return mean_squared_error\n",
    "\n",
    "\n",
    "def custom_objects_dict():\n",
    "    cutom_objects = {\n",
    "        \"TFCamembertModel\": TFCamembertModel, \n",
    "        \"custom_loss\": custom_loss, \n",
    "        \"custom_metric\": custom_metric,\n",
    "    }\n",
    "    return cutom_objects\n",
    "\n",
    "\n",
    "def custom_metric(y_true, y_pred):\n",
    "    # intervals = ['[1825, 1850)', '[1850, 1875)', '[1875, 1900)', '[1900, 1925)', '[1925, 1950)', '[1950, 1975)', '[1975, 2000)', '[2000, 2024)']\n",
    "    estimated_years = calculate_estimated_year_tensor(list(config.DATE_MAP.values()), y_pred)\n",
    "    # estimated_years = calculate_estimated_year_tensor(intervals, y_pred)\n",
    "    # Convertir y_true en float32 sans changer la shape\n",
    "    y_true_float = tf.cast(y_true, tf.float32)\n",
    "    # Aplatir y_true pour correspondre à estimated_years\n",
    "    y_true_flat = tf.reshape(y_true_float, [-1])\n",
    "    # Calcul de la précision\n",
    "    correct_predictions = tf.abs(estimated_years - y_true_flat) <= 25\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def evaluate_model(df: pd.DataFrame, confusion_matrix_output: str, roc_curve_output: str):\n",
    "    plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "    true_sexe = np.array(df[\"true sexe\"].tolist())\n",
    "    pred_sexe = np.array(df[\"pred sexe\"].tolist())\n",
    "    true_date = np.array(df[\"true date\"].tolist())\n",
    "\n",
    "    # Sexe metrics\n",
    "    accuracy_sexe = accuracy_score(true_sexe, pred_sexe)\n",
    "    precision_sexe = precision_score(true_sexe, pred_sexe)\n",
    "    recall_sexe = recall_score(true_sexe, pred_sexe)\n",
    "    f1_sexe = f1_score(true_sexe, pred_sexe)\n",
    "    auc_sexe = roc_auc_score(true_sexe, pred_sexe)\n",
    "\n",
    "    print(f\"\\nSexe - Accuracy: {accuracy_sexe} \\nPrecision: {precision_sexe} \\nRecall: {recall_sexe} \\nF1 Score: {f1_sexe} \\nAUC: {auc_sexe}\\n\")\n",
    "\n",
    "    # Enregistrement des métriques dans un .json\n",
    "    metrics = {\n",
    "        \"accuracy_sexe\": accuracy_sexe,\n",
    "        \"precision_sexe\": precision_sexe,\n",
    "        \"recall_sexe\": recall_sexe,\n",
    "        \"f1_sexe\": f1_sexe,\n",
    "        \"auc_sexe\": auc_sexe\n",
    "    }\n",
    "\n",
    "    with open(config.MM_CNN_RESULT_PATH + f\"{config.MM_CNN}_predictions_metrics.json\", \"w\") as json_file:\n",
    "        json.dump(metrics, json_file, indent=4)\n",
    "\n",
    "    # Confusion matrix\n",
    "\n",
    "    plt.style.use(\"seaborn-v0_8-white\")\n",
    "    # Convert predictions to binary\n",
    "    pred_binary = (pred_sexe > 0.5).astype(int)\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(true_sexe, pred_binary)\n",
    "    # Normalize the confusion matrix to display rates\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    # Plot confusion matrix with updated display labels\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm_normalized, display_labels=[\"Femme\", \"Homme\"])\n",
    "    disp.plot(cmap=plt.cm.Blues, values_format=\".2f\")  # Set the colormap to Blues and format to 2 decimal places\n",
    "    plt.title(f\"Matrice de confusion - Sexe\")\n",
    "    plt.savefig(confusion_matrix_output)\n",
    "    plt.close()\n",
    "\n",
    "    # Plot ROC curve\n",
    "    fpr, tpr, _ = roc_curve(true_sexe, pred_sexe)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color=\"blue\", lw=2, label=\"ROC curve (AUC = %0.2f)\" % auc_sexe)\n",
    "    plt.plot([0, 1], [0, 1], color=\"grey\", lw=2, linestyle=\"--\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Receiver Operating Characteristic - Sexe\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(roc_curve_output)\n",
    "    plt.close()\n",
    "\n",
    "    return accuracy_sexe, precision_sexe, recall_sexe, f1_sexe, auc_sexe\n",
    "\n",
    "\n",
    "def prediction(model, input_data, sexe_label, date_label=None):\n",
    "    test_predictions = model.predict(input_data)\n",
    "\n",
    "    if len(test_predictions) == 2:\n",
    "        # Unpack predictions\n",
    "        pred_sexe = np.squeeze((test_predictions[0] > 0.5).astype(\"int32\"))\n",
    "        pred_date = test_predictions[1]\n",
    "    else:\n",
    "        pred_sexe = np.squeeze((test_predictions > 0.5).astype(\"int32\"))\n",
    "        \n",
    "    true_sexe = np.array(sexe_label).astype(\"int32\")\n",
    "    true_date = np.array(date_label).astype(\"int32\") if date_label is not None else None\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        \"true sexe\": true_sexe,\n",
    "        \"pred sexe\": pred_sexe,\n",
    "        \"true date\": true_date,\n",
    "        # \"pred date\": pred_date,\n",
    "    })\n",
    "    return df\n",
    "\n",
    "\n",
    "def save_accuracy_by_interval_and_gender(df: pd.DataFrame, output_file: str):\n",
    "    \"\"\"\n",
    "    Prépare les données pour calculer l'accuracy pour chaque sexe et chaque intervalle,\n",
    "    puis trace un histogramme à barres pour l'accuracy par intervalle et sexe.\n",
    "\n",
    "    Arguments :\n",
    "    df : DataFrame - Le DataFrame contenant les données à analyser.\n",
    "    \"\"\"\n",
    "    plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "    # Préparer les données pour l'accuracy\n",
    "    intervals = df[\"interval\"].unique()\n",
    "    data_for_plot = []\n",
    "\n",
    "    for interval in intervals:\n",
    "        df_interval = df[df[\"interval\"] == interval]\n",
    "        for sex in [0, 1]:  # 0: Femme, 1: Homme\n",
    "            df_sex = df_interval[df_interval[\"true sexe\"] == sex]\n",
    "            cm = confusion_matrix(df_sex[\"true sexe\"], df_sex[\"pred sexe\"])\n",
    "            total = cm.sum()\n",
    "            correct_predictions = cm.trace()  # Sum of True Positives and True Negatives\n",
    "            accuracy = correct_predictions / total\n",
    "            # gender = \"Femme\" if sex == 0 else \"Homme\"\n",
    "            gender = \"Femme\" if sex == 0 else \"Homme\"\n",
    "            data_for_plot.append((interval, gender, accuracy))\n",
    "    \n",
    "    df_accuracy = pd.DataFrame(data_for_plot, columns=[\"Interval\", \"Gender\", \"Accuracy\"])\n",
    "\n",
    "    # Tracer l'histogramme à barres pour l'accuracy par intervalle et sexe\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    ax = sns.barplot(x=\"Interval\", y=\"Accuracy\", hue=\"Gender\", data=df_accuracy, palette=[\"#FF7F0E\", \"#1F77B4\"])\n",
    "    plt.xlabel(\"Intervalles\")\n",
    "    plt.ylabel(\"Taux d\\'accuracy\")\n",
    "    plt.title(\"Taux d\\'accuracy par intervalle et sexe\")\n",
    "    plt.xticks(rotation=45)\n",
    "    # plt.legend(title=\"Sexe\")\n",
    "    plt.legend(title=\"Sexe\", loc=\"upper right\", frameon=True)\n",
    "    # plt.legend(title=\"Sexe\", loc='upper right', fontsize=12, title_fontsize=14, frameon=True, fancybox=False, framealpha=1, shadow=False, borderpad=1)\n",
    "    plt.ylim(0, 1)  # Limiter l'axe Y entre 0 et 1\n",
    "\n",
    "    # Ajouter les valeurs d'accuracy au-dessus de chaque barre\n",
    "    for p in ax.patches:\n",
    "        if p.get_height() != 0.00:\n",
    "            ax.annotate(f\"{p.get_height():.2f}\", \n",
    "                    (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha=\"center\", va=\"bottom\", fontsize=8, color=\"black\", xytext=(0, 5), textcoords=\"offset points\")\n",
    "\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def save_hist_confusion_matrix(df: pd.DataFrame, output_file: str):\n",
    "    \"\"\"\n",
    "    Prépare les données et trace l'histogramme de la matrice de confusion normalisée par intervalle et sexe.\n",
    "\n",
    "    Arguments :\n",
    "    df : DataFrame - Le DataFrame contenant les données à analyser.\n",
    "\n",
    "    Renvoie :\n",
    "    None\n",
    "    \"\"\"\n",
    "    def prepare_confusion_data(df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Prépare les données pour la matrice de confusion normalisée.\n",
    "\n",
    "        Arguments :\n",
    "        df : DataFrame - Le DataFrame contenant les données à analyser.\n",
    "\n",
    "        Renvoie :\n",
    "        DataFrame - Un DataFrame contenant les données de la matrice de confusion normalisée.\n",
    "        \"\"\"\n",
    "        # Obtenir les intervalles uniques\n",
    "        intervals = df[\"interval\"].unique()\n",
    "        data_for_plot = []\n",
    "\n",
    "        # Parcourir chaque intervalle\n",
    "        for interval in intervals:\n",
    "            # Filtrer le DataFrame pour l'intervalle actuel\n",
    "            df_interval = df[df[\"interval\"] == interval]\n",
    "            # Parcourir les deux sexes (0: Femme, 1: Homme)\n",
    "            for sex in [0, 1]:\n",
    "                # Filtrer le DataFrame pour le sexe actuel\n",
    "                df_sex = df_interval[df_interval[\"true sexe\"] == sex]\n",
    "                # Calculer la matrice de confusion\n",
    "                cm = confusion_matrix(df_sex[\"true sexe\"], df_sex[\"pred sexe\"])\n",
    "                # Calculer le total des prédictions\n",
    "                total = cm.sum()\n",
    "                print(\"total\")\n",
    "                # Normaliser la matrice de confusion\n",
    "                cm_normalized = cm / total\n",
    "                # Déterminer le genre (Femme ou Homme)\n",
    "                gender = \"Femme\" if sex == 0 else \"Homme\"\n",
    "                # Parcourir la matrice de confusion normalisée\n",
    "                for i, row in enumerate(cm_normalized):\n",
    "                    for j, val in enumerate(row):\n",
    "                        # Déterminer la catégorie (Vrai ou Faux)\n",
    "                        category = \"True\" if i == j else \"False\"\n",
    "                        data_for_plot.append((interval, f\"{category} {gender}\", val))\n",
    "        \n",
    "        # Créer un DataFrame à partir des données\n",
    "        return pd.DataFrame(data_for_plot, columns=[\"Interval\", \"Category\", \"Value\"])\n",
    "    plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "    # Préparer les données\n",
    "    df_plot = prepare_confusion_data(df)\n",
    "\n",
    "    # Utiliser la palette tab10 de seaborn\n",
    "    colors = sns.color_palette(\"tab10\")\n",
    "\n",
    "    # Créer une palette avec les couleurs spécifiées pour chaque catégorie\n",
    "    custom_palette = {\"True Femme\": colors[1], \"True Homme\": colors[0]}\n",
    "    palette = {**custom_palette, **{category: colors[i+2] for i, category in enumerate(df_plot[\"Category\"].unique()) if category not in custom_palette}}\n",
    "\n",
    "    # Tracer l'histogramme à barres avec la palette personnalisée\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    ax = sns.barplot(x=\"Interval\", y=\"Value\", hue=\"Category\", data=df_plot, palette=palette)\n",
    "    plt.xlabel(\"Intervalles\")\n",
    "    plt.ylabel(\"Proportion\")\n",
    "    plt.title(\"Histogramme des matrices de confusions par intervalle et sexe\")\n",
    "    plt.xticks(rotation=45)\n",
    "    # plt.legend(title=\"Prédictions\")\n",
    "    plt.legend(title=\"Prédictions\", loc=\"upper right\", frameon=True)\n",
    "    plt.ylim(0, 1)  # Limiter l'axe Y entre 0 et 1\n",
    "\n",
    "    # Ajouter les valeurs normalisées au-dessus de chaque barre\n",
    "    for p in ax.patches:\n",
    "        if p.get_height() != 0.00:\n",
    "            ax.annotate(f'{p.get_height():.2f}', \n",
    "                        (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                        ha=\"center\", va=\"bottom\", fontsize=8, color=\"black\", xytext=(3, 5), textcoords=\"offset points\")\n",
    "\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def save_training_history(history_data: dict, save_dir: str=\"plots\", base_filename: str=\"plot\", single_figure: bool=False):\n",
    "    \"\"\"\n",
    "    Save the training history for a model and save the figures.\n",
    "\n",
    "    Parameters:\n",
    "    history (History): The training history returned by model.fit()\n",
    "    save_dir (str): Directory to save the plots\n",
    "    base_filename (str): Base filename for the saved plots\n",
    "    single_figure (bool): Whether to save all plots in a single figure\n",
    "    \"\"\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    # Function to annotate values on the plot\n",
    "    def annotate_values(ax, x, y):\n",
    "        for i, txt in enumerate(y):\n",
    "            ax.annotate(round(txt, 2), (x[i], y[i]), textcoords=\"offset points\", xytext=(0, 5), ha=\"center\")\n",
    "\n",
    "    # Set the style\n",
    "    plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "\n",
    "    if single_figure:\n",
    "        # Determine the number of unique keys (excluding validation keys)\n",
    "        unique_keys = set(key.replace(\"val_\", \"\") for key in history_data.keys())\n",
    "        num_plots = len(unique_keys)\n",
    "        fig, axs = plt.subplots(num_plots, 1, figsize=(15, num_plots * 5))\n",
    "        \n",
    "        if num_plots == 1:\n",
    "            axs = [axs]\n",
    "\n",
    "        for i, key in enumerate(unique_keys):\n",
    "            train_key = key\n",
    "            val_key = \"val_\" + key\n",
    "\n",
    "            axs[i].plot(history_data[train_key], label=f\"Training {train_key.replace('_', ' ').title()}\", marker=\"o\")\n",
    "            if val_key in history_data:\n",
    "                axs[i].plot(history_data[val_key], label=f\"{val_key.replace('_', ' ').title()}\", marker=\"o\")\n",
    "            \n",
    "            axs[i].set_xlabel(\"Epochs\")\n",
    "            axs[i].set_ylabel(train_key.split(\"_\")[-1].title())\n",
    "            axs[i].set_title(train_key.replace(\"_\", \" \").title())\n",
    "            axs[i].legend()\n",
    "            axs[i].grid(True)\n",
    "\n",
    "            annotate_values(axs[i], range(len(history_data[train_key])), history_data[train_key])\n",
    "            if val_key in history_data:\n",
    "                annotate_values(axs[i], range(len(history_data[val_key])), history_data[val_key])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(save_dir, f\"{base_filename}_combined.png\"))\n",
    "        plt.close()\n",
    "    else:\n",
    "        for key in set(key.replace(\"val_\", \"\") for key in history_data.keys()):\n",
    "            train_key = key\n",
    "            val_key = \"val_\" + key\n",
    "\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.plot(history_data[train_key], label=f\"Train {train_key.replace('_', ' ').title()}\", marker=\"o\")\n",
    "            if val_key in history_data:\n",
    "                plt.plot(history_data[val_key], label=f\"{val_key.replace('_', ' ').title()}\", marker=\"o\")\n",
    "\n",
    "            plt.xlabel(\"Epochs\")\n",
    "            plt.ylabel(train_key.split(\"_\")[-1].title())\n",
    "            plt.title(train_key.replace(\"_\", \" \").title())\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            annotate_values(plt.gca(), range(len(history_data[train_key])), history_data[train_key])\n",
    "            if val_key in history_data:\n",
    "                annotate_values(plt.gca(), range(len(history_data[val_key])), history_data[val_key])\n",
    "            \n",
    "            plt.savefig(os.path.join(save_dir, f\"{base_filename}_{train_key}.png\"))\n",
    "            plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mm_cnn(\n",
    "    num_date_classes:int ,\n",
    "    model_id: str=None,\n",
    "    max_length: int=514,\n",
    "    dense_units: int=16,\n",
    "    conv_filters: int=32, \n",
    "    conv_kernel_size: int=3, \n",
    "):\n",
    "    \"\"\"\n",
    "    Crée un modèle Keras avec un modèle BERT pré-entraîné pour une tâche multitâche de classification.\n",
    "\n",
    "    Parameters:\n",
    "    - model_id: str, identifiant du modèle pré-entraîné à utiliser (par exemple, 'bert-base-uncased')\n",
    "    - max_length: int, la longueur maxiHomme des séquences d'entrée\n",
    "    - dense_units: int, nombre d'unités pour les couches denses individuelles\n",
    "    - concat_dense_units: int, nombre d'unités pour la couche dense après concaténation\n",
    "\n",
    "    Returns:\n",
    "    - model: Keras Model, le modèle compilé\n",
    "    \"\"\"\n",
    "    # Charger le modèle BERT pré-entraîné\n",
    "    bert_model = TFAutoModel.from_pretrained(model_id)\n",
    "\n",
    "    # Définir les entrées du modèle\n",
    "    input_ids = Input(shape=(max_length,), dtype=tf.int32, name=\"input_ids\")\n",
    "    attention_mask = Input(shape=(max_length,), dtype=tf.int32, name=\"attention_mask\")\n",
    "\n",
    "    # Passer les entrées dans le modèle BERT\n",
    "    bert_output = bert_model(input_ids, attention_mask=attention_mask) \n",
    "    sequence_output = bert_output.last_hidden_state  # Shape: (batch_size, sequence_length, hidden_size)  Utiliser ensuite avec un CNN\n",
    "    # pooled_output = bert_output.pooler_output  # Shape: (batch_size, hidden_size) # Utiliser le pooled_output pour la classification\n",
    "\n",
    "    # CNN\n",
    "    conv_layer = Conv1D(filters=conv_filters, kernel_size=conv_kernel_size, activation=\"relu\", name=\"Conv1D\")(sequence_output)\n",
    "    pooling_layer = MaxPooling1D(pool_size=2, name=\"MaxPooling1D\")(conv_layer)\n",
    "    flatten_layer = Flatten(name=\"Flatten\")(pooling_layer)\n",
    "    dropout_layer = Dropout(0.3, name=\"Dropout\")(flatten_layer) # Ajout des couches supplémentaires pour les tâches spécifiques\n",
    "\n",
    "    # Dense layers for individual tasks\n",
    "    dense_layer = Dense(units=dense_units, activation=\"relu\", name=\"Dense\")(dropout_layer)\n",
    "\n",
    "    # Output layers for individual tasks\n",
    "    sexe_output = Dense(1, activation=\"sigmoid\", name=\"Sexe_output\")(dense_layer)\n",
    "    date_output = Dense(num_date_classes, activation=\"softmax\", name=\"Date_output\")(dense_layer)\n",
    "\n",
    "    # Créer le modèle\n",
    "    model = Model(inputs=[input_ids, attention_mask], outputs=[sexe_output, date_output])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFCamembertModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing TFCamembertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFCamembertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFCamembertModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_camembert_model/roberta/pooler/dense/kernel:0', 'tf_camembert_model/roberta/pooler/dense/bias:0', 'Date_output/kernel:0', 'Date_output/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_camembert_model/roberta/pooler/dense/kernel:0', 'tf_camembert_model/roberta/pooler/dense/bias:0', 'Date_output/kernel:0', 'Date_output/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "10/10 [==============================] - ETA: 0s - loss: 1.6139 - Sexe_output_loss: 0.9594 - Date_output_loss: 6545.2583 - Sexe_output_accuracy: 0.4901 - Date_output_custom_metric: 0.2188\n",
      "Epoch 1: val_loss improved from inf to 1.39482, saving model to ../results/mm_cnn\\mm_cnn_best_model.h5\n",
      "10/10 [==============================] - 23s 1s/step - loss: 1.6139 - Sexe_output_loss: 0.9594 - Date_output_loss: 6545.2583 - Sexe_output_accuracy: 0.4901 - Date_output_custom_metric: 0.2188 - val_loss: 1.3948 - val_Sexe_output_loss: 0.7456 - val_Date_output_loss: 6492.5234 - val_Sexe_output_accuracy: 0.4582 - val_Date_output_custom_metric: 0.2049\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - ETA: 0s - loss: 1.3826 - Sexe_output_loss: 0.7242 - Date_output_loss: 6584.5366 - Sexe_output_accuracy: 0.5828 - Date_output_custom_metric: 0.2205\n",
      "Epoch 2: val_loss did not improve from 1.39482\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "10/10 [==============================] - 9s 934ms/step - loss: 1.3826 - Sexe_output_loss: 0.7242 - Date_output_loss: 6584.5366 - Sexe_output_accuracy: 0.5828 - Date_output_custom_metric: 0.2205 - val_loss: 1.4087 - val_Sexe_output_loss: 0.7263 - val_Date_output_loss: 6823.9639 - val_Sexe_output_accuracy: 0.5236 - val_Date_output_custom_metric: 0.2049\n",
      "Epoch 2: early stopping\n",
      "7/7 [==============================] - 3s 359ms/step - loss: 1.4531 - Sexe_output_loss: 0.7266 - Date_output_loss: 7265.2969 - Sexe_output_accuracy: 0.5495 - Date_output_custom_metric: 0.1607\n",
      "\n",
      "Evaluation...\n",
      "\n",
      "{'loss': 1.4530818462371826,\n",
      " 'Sexe_output_loss': 0.7265522480010986,\n",
      " 'Date_output_loss': 7265.296875,\n",
      " 'Sexe_output_accuracy': 0.5495049357414246,\n",
      " 'Date_output_custom_metric': 0.1607142835855484}\n",
      "\n",
      "Prédictions...\n",
      "\n",
      "7/7 [==============================] - 4s 357ms/step\n",
      "\n",
      "Sexe - Accuracy: 0.5495049504950495 \n",
      "Precision: 0.5566037735849056 \n",
      "Recall: 0.5728155339805825 \n",
      "F1 Score: 0.5645933014354068 \n",
      "AUC: 0.5490340296165539\n",
      "\n",
      "total\n",
      "total\n",
      "total\n",
      "total\n",
      "total\n",
      "total\n",
      "total\n",
      "total\n",
      "total\n",
      "total\n",
      "total\n",
      "total\n",
      "total\n",
      "total\n",
      "total\n",
      "total\n"
     ]
    }
   ],
   "source": [
    "# 1 : Charger les données d'entraînements et de validation\n",
    "inputs_and_labels = data.main()\n",
    "\n",
    "train_inputs = inputs_and_labels[\"train_inputs\"]\n",
    "train_sexe_labels = inputs_and_labels[\"train_sexe_labels\"]\n",
    "train_date_labels = inputs_and_labels[\"train_date_labels\"]\n",
    "\n",
    "val_inputs = inputs_and_labels[\"val_inputs\"]\n",
    "val_sexe_labels = inputs_and_labels[\"val_sexe_labels\"]\n",
    "val_date_labels = inputs_and_labels[\"val_date_labels\"]\n",
    "\n",
    "# Libérer la mémoire occupée par inputs_and_labels\n",
    "del inputs_and_labels\n",
    "\n",
    "# Créer le répertoire s'il n'existe pas\n",
    "os.makedirs(config.MM_CNN_RESULT_PATH, exist_ok=True)\n",
    "\n",
    "# 1. Intialiser le modèle\n",
    "model = mm_cnn(num_date_classes=len(config.DATE_MAP), model_id=config.MODEL_ID)\n",
    "\n",
    "# 2. Compiler le modèle avec les fonctions de perte appropriées pour chaque sortie\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "    loss={\n",
    "        \"Sexe_output\": \"binary_crossentropy\", \n",
    "        \"Date_output\": custom_loss,\n",
    "    },\n",
    "    loss_weights={\n",
    "        \"Sexe_output\": config.SEXE_LOSS_WEIGHT,\n",
    "        \"Date_output\": config.DATE_LOSS_WEIGHT\n",
    "    },\n",
    "    metrics={\n",
    "        \"Sexe_output\": \"accuracy\", \n",
    "        \"Date_output\": custom_metric,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Sauvegarder l'architecture du modèle en .png\n",
    "plot_model(model=model, show_shapes=True, to_file=config.MM_CNN_RESULT_PATH + f\"{config.MM_CNN}_model_arch.png\")\n",
    "\n",
    "# Callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=config.MM_CNN_RESULT_PATH + f\"{config.MM_CNN}_best_model.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    mode=\"min\", # Sauvegarder le modèle avec la perte minimale\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Early stopping\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=config.PATIENCE,\n",
    "    verbose=1, # Affichage d'un message\n",
    "    restore_best_weights=True # Restaurer les poids du meilleur modèle après l'arrêt\n",
    ")\n",
    "\n",
    "# 3. Entraîner le modèle\n",
    "history = model.fit(\n",
    "    x=train_inputs,\n",
    "    y={\n",
    "        \"Sexe_output\": train_sexe_labels, \n",
    "        \"Date_output\": train_date_labels,\n",
    "        },\n",
    "    epochs=config.EPOCHS,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    callbacks=[\n",
    "        checkpoint_callback, \n",
    "        early_stopping_callback,\n",
    "    ],\n",
    "    validation_data=(\n",
    "        val_inputs, \n",
    "        {\n",
    "            \"Sexe_output\": val_sexe_labels, \n",
    "            \"Date_output\": val_date_labels,\n",
    "        }),\n",
    ")\n",
    "    \n",
    "# Sauvegarder l'historique de l'entraînement en .json\n",
    "with open(config.MM_CNN_RESULT_PATH + f\"{config.MM_CNN}_history.json\", \"w\") as json_file:\n",
    "    json.dump(history.history, json_file, indent=4)\n",
    "# Sauvegarder l'historique de l'entraînement en .png\n",
    "save_training_history(history_data=history.history, save_dir=config.MM_CNN_RESULT_PATH, base_filename=config.MM_CNN, single_figure=True)\n",
    "save_training_history(history_data=history.history, save_dir=config.MM_CNN_RESULT_PATH, base_filename=config.MM_CNN, single_figure=False)\n",
    "\n",
    "\n",
    "# Evaluation --------------------------------\n",
    "\n",
    "\n",
    "# 1. Charger les données de tests\n",
    "inputs_and_labels = data.main()\n",
    "\n",
    "test_inputs = inputs_and_labels[\"test_inputs\"]\n",
    "test_sexe_labels = inputs_and_labels[\"test_sexe_labels\"]\n",
    "test_date_labels = inputs_and_labels[\"test_date_labels\"]\n",
    "\n",
    "# Libérer la mémoire occupée par inputs_and_labels\n",
    "del inputs_and_labels\n",
    "\n",
    "# Évaluer le modèle sur les données de test avec le GPU\n",
    "evaluation_results = model.evaluate(\n",
    "    x = test_inputs,\n",
    "    y = {\n",
    "        \"Sexe_output\": np.array(test_sexe_labels),\n",
    "        \"Date_output\": np.array(test_date_labels),\n",
    "    },\n",
    "    return_dict=True\n",
    ")\n",
    "    \n",
    "print(\"\\nEvaluation...\\n\")\n",
    "pprint.pp(evaluation_results)\n",
    "\n",
    "# Sauvegarder les résultats de l'évaluation\n",
    "with open(config.MM_CNN_RESULT_PATH + f\"{config.MM_CNN}_evaluation_results.json\", \"w\") as json_file:\n",
    "    json.dump(evaluation_results, json_file, indent=4)\n",
    "    \n",
    "# Charger le modèle pré entraîné\n",
    "# model = load_model(\n",
    "#     filepath=config.MM_CNN_RESULT_PATH + f\"{config.MM_CNN}_best_model.h5\", \n",
    "#     custom_objects=custom_objects_dict()\n",
    "# )\n",
    "\n",
    "print(\"\\nPrédictions...\\n\")\n",
    "prediction_df = prediction(model=model, input_data=test_inputs, sexe_label=test_sexe_labels, date_label=test_date_labels)\n",
    "\n",
    "evaluate_model(\n",
    "    df=prediction_df, \n",
    "    confusion_matrix_output=config.MM_CNN_RESULT_PATH + f\"{config.MM_CNN}_confusion_matrix.png\", \n",
    "    roc_curve_output=config.MM_CNN_RESULT_PATH + f\"{config.MM_CNN}_roc_curve.png\"\n",
    ")\n",
    "\n",
    "def map_true_date_to_interval(date):\n",
    "    for _, value in config.DATE_MAP.items():\n",
    "        start, end = map(int, value.strip(\"[]()\").split(\", \"))\n",
    "        if start <= date < end:\n",
    "            return value\n",
    "    return None  # Return None if date does not fall into any defined interval\n",
    "\n",
    "# Apply the mapping function to populate the interval column\n",
    "prediction_df[\"interval\"] = prediction_df[\"true date\"].apply(map_true_date_to_interval)\n",
    "\n",
    "save_hist_confusion_matrix(df=prediction_df, output_file=config.MM_CNN_RESULT_PATH + f\"{config.MM_CNN}_hist_confusion_matrix.png\")\n",
    "\n",
    "save_accuracy_by_interval_and_gender(df=prediction_df, output_file=config.MM_CNN_RESULT_PATH + f\"{config.MM_CNN}_accuracy_by_interval_sexes.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_date_to_interval(date):\n",
    "    if 1825 <= date < 1850:\n",
    "        return config.DATE_MAP[0]\n",
    "    elif 1850 <= date < 1875:\n",
    "        return config.DATE_MAP[1]\n",
    "    elif 1875 <= date < 1900:\n",
    "        return config.DATE_MAP[2]\n",
    "    elif 1900 <= date < 1925:\n",
    "        return config.DATE_MAP[3]\n",
    "    elif 1925 <= date < 1950:\n",
    "        return config.DATE_MAP[4]\n",
    "    elif 1950 <= date < 1975:\n",
    "        return config.DATE_MAP[5]\n",
    "    elif 1975 <= date < 2000:\n",
    "        return config.DATE_MAP[6]\n",
    "    elif 2000 <= date < 2024:\n",
    "        return config.DATE_MAP[7]\n",
    "    else:\n",
    "        return float('nan')\n",
    "\n",
    "# Appliquer la fonction à la colonne 'true date'\n",
    "prediction_df[\"interval\"] = prediction_df[\"true date\"].apply(map_date_to_interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map true date to interval\n",
    "def map_true_date_to_interval(date):\n",
    "    for key, value in config.DATE_MAP.items():\n",
    "        start, end = map(int, value.strip('[]()').split(', '))\n",
    "        if start <= date < end:\n",
    "            return value\n",
    "    return None  # Return None if date does not fall into any defined interval\n",
    "\n",
    "# Apply the mapping function to populate the interval column\n",
    "prediction_df['interval'] = prediction_df['true date'].apply(map_true_date_to_interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true sexe</th>\n",
       "      <th>pred sexe</th>\n",
       "      <th>true date</th>\n",
       "      <th>interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1827</td>\n",
       "      <td>[1825, 1850)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1831</td>\n",
       "      <td>[1825, 1850)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1832</td>\n",
       "      <td>[1825, 1850)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1832</td>\n",
       "      <td>[1825, 1850)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1832</td>\n",
       "      <td>[1825, 1850)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>[2000, 2024)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>[2000, 2024)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "      <td>[2000, 2024)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>[2000, 2024)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "      <td>[2000, 2024)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     true sexe  pred sexe  true date      interval\n",
       "0            1          0       1827  [1825, 1850)\n",
       "1            1          0       1831  [1825, 1850)\n",
       "2            0          0       1832  [1825, 1850)\n",
       "3            0          0       1832  [1825, 1850)\n",
       "4            0          0       1832  [1825, 1850)\n",
       "..         ...        ...        ...           ...\n",
       "197          0          0       2017  [2000, 2024)\n",
       "198          0          1       2017  [2000, 2024)\n",
       "199          0          0       2022  [2000, 2024)\n",
       "200          0          1       2022  [2000, 2024)\n",
       "201          0          0       2022  [2000, 2024)\n",
       "\n",
       "[202 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true sexe</th>\n",
       "      <th>pred sexe</th>\n",
       "      <th>true date</th>\n",
       "      <th>interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1827</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1831</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1832</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1832</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1832</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     true sexe  pred sexe  true date interval\n",
       "0            1          1       1827      NaN\n",
       "1            1          1       1831      NaN\n",
       "2            0          0       1832      NaN\n",
       "3            0          0       1832      NaN\n",
       "4            0          0       1832      NaN\n",
       "..         ...        ...        ...      ...\n",
       "197          0          0       2017      NaN\n",
       "198          0          0       2017      NaN\n",
       "199          0          0       2022      NaN\n",
       "200          0          0       2022      NaN\n",
       "201          0          0       2022      NaN\n",
       "\n",
       "[202 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '[1825, 1850)',\n",
       " 1: '[1850, 1875)',\n",
       " 2: '[1875, 1900)',\n",
       " 3: '[1900, 1925)',\n",
       " 4: '[1925, 1950)',\n",
       " 5: '[1950, 1975)',\n",
       " 6: '[1975, 2000)',\n",
       " 7: '[2000, 2024)'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.DATE_MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      NaN\n",
       "1      NaN\n",
       "2      NaN\n",
       "3      NaN\n",
       "4      NaN\n",
       "      ... \n",
       "197    NaN\n",
       "198    NaN\n",
       "199    NaN\n",
       "200    NaN\n",
       "201    NaN\n",
       "Name: true date, Length: 202, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df[\"true date\"].map(config.DATE_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true sexe</th>\n",
       "      <th>pred sexe</th>\n",
       "      <th>true date</th>\n",
       "      <th>interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1827</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1831</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1832</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1832</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1832</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     true sexe  pred sexe  true date interval\n",
       "0            1          1       1827      NaN\n",
       "1            1          1       1831      NaN\n",
       "2            0          0       1832      NaN\n",
       "3            0          0       1832      NaN\n",
       "4            0          0       1832      NaN\n",
       "..         ...        ...        ...      ...\n",
       "197          0          0       2017      NaN\n",
       "198          0          0       2017      NaN\n",
       "199          0          0       2022      NaN\n",
       "200          0          0       2022      NaN\n",
       "201          0          0       2022      NaN\n",
       "\n",
       "[202 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import data\n",
    "import os\n",
    "\n",
    "from transformers import TFAutoModel\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import (\n",
    "    Concatenate,\n",
    "    Conv1D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    # Embedding,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    MaxPooling1D,\n",
    ")\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "\n",
    "from training_functions import (\n",
    "    # calculate_estimated_year_tensor,\n",
    "    custom_loss,\n",
    "    # custom_objects_dict,\n",
    "    custom_metric,\n",
    "    evaluate_model,\n",
    "    prediction,\n",
    "    save_accuracy_by_interval_and_gender,\n",
    "    save_hist_confusion_matrix,\n",
    "    save_training_history,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def ss_cnn(\n",
    "    model_id: str=None,\n",
    "    max_length: int=514,\n",
    "    dense_units: int=16,\n",
    "    conv_filters: int=32, \n",
    "    conv_kernel_size: int=3, \n",
    "):\n",
    "    \"\"\"\n",
    "    Crée un modèle Keras avec un modèle BERT pré-entraîné pour une tâche de classification du sexe.\n",
    "\n",
    "    Parameters:\n",
    "    - model_id: str, identifiant du modèle pré-entraîné à utiliser (par exemple, 'bert-base-uncased')\n",
    "    - max_length: int, la longueur maxiHomme des séquences d'entrée\n",
    "    - dense_units: int, nombre d'unités pour les couches denses\n",
    "    - conv_filters: int, nombre de filtres pour la couche Conv1D\n",
    "    - conv_kernel_size: int, taille du noyau pour la couche Conv1D\n",
    "\n",
    "    Returns:\n",
    "    - model: Keras Model, le modèle compilé\n",
    "    \"\"\"\n",
    "    # Charger le modèle BERT pré-entraîné\n",
    "    bert_model = TFAutoModel.from_pretrained(model_id)\n",
    "\n",
    "    # Définir les entrées du modèle\n",
    "    input_ids = Input(shape=(max_length,), dtype=tf.int32, name=\"input_ids\")\n",
    "    attention_mask = Input(shape=(max_length,), dtype=tf.int32, name=\"attention_mask\")\n",
    "\n",
    "    # Passer les entrées dans le modèle BERT\n",
    "    bert_output = bert_model(input_ids, attention_mask=attention_mask)\n",
    "    sequence_output = bert_output.last_hidden_state  # Shape: (batch_size, sequence_length, hidden_size)\n",
    "\n",
    "    # CNN\n",
    "    conv_layer = Conv1D(filters=conv_filters, kernel_size=conv_kernel_size, activation=\"relu\", name=\"Conv1D\")(sequence_output)\n",
    "    pooling_layer = MaxPooling1D(pool_size=2, name=\"MaxPooling1D\")(conv_layer)\n",
    "    flatten_layer = Flatten(name=\"Flatten\")(pooling_layer)\n",
    "    dropout_layer = Dropout(0.3, name=\"Dropout\")(flatten_layer)\n",
    "\n",
    "    # Dense layer for sex classification\n",
    "    dense_layer_sexe = Dense(units=dense_units, activation=\"relu\", name=\"Dense_sexe\")(dropout_layer)\n",
    "\n",
    "    # Output layer for sex classification\n",
    "    sexe_output = Dense(1, activation=\"sigmoid\", name=\"Sexe_output\")(dense_layer_sexe)\n",
    "\n",
    "    # Créer le modèle\n",
    "    model = Model(inputs=[input_ids, attention_mask], outputs=sexe_output)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 1 : Charger les données d'entraînements et de validation\n",
    "    inputs_and_labels = data.main()\n",
    "\n",
    "    train_inputs = inputs_and_labels[\"train_inputs\"]\n",
    "    train_sexe_labels = inputs_and_labels[\"train_sexe_labels\"]\n",
    "    # train_date_labels = inputs_and_labels[\"train_date_labels\"]\n",
    "\n",
    "    val_inputs = inputs_and_labels[\"val_inputs\"]\n",
    "    val_sexe_labels = inputs_and_labels[\"val_sexe_labels\"]\n",
    "    # val_date_labels = inputs_and_labels[\"val_date_labels\"]\n",
    "\n",
    "    # Libérer la mémoire occupée par inputs_and_labels\n",
    "    del inputs_and_labels\n",
    "\n",
    "    # Créer le répertoire s'il n'existe pas\n",
    "    os.makedirs(config.SS_CNN_RESULT_PATH, exist_ok=True)\n",
    "\n",
    "    # 1. Intialiser le modèle\n",
    "    model = ss_cnn(model_id=config.MODEL_ID)\n",
    "\n",
    "    # 2. Compiler le modèle avec les fonctions de perte appropriées pour chaque sortie\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "        loss={\n",
    "            \"Sexe_output\": \"binary_crossentropy\", \n",
    "            # \"Date_output\": custom_loss,\n",
    "        },\n",
    "        loss_weights={\n",
    "            \"Sexe_output\": config.SEXE_LOSS_WEIGHT,\n",
    "            # \"Date_output\": config.DATE_LOSS_WEIGHT\n",
    "        },\n",
    "        metrics={\n",
    "            \"Sexe_output\": \"accuracy\", \n",
    "            # \"Date_output\": custom_metric,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Sauvegarder l'architecture du modèle en .png\n",
    "    plot_model(model=model, show_shapes=True, to_file=config.SS_CNN_RESULT_PATH + f\"{config.SS_CNN}_model_arch.png\")\n",
    "\n",
    "    # Callbacks\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=config.SS_CNN_RESULT_PATH + f\"{config.SS_CNN}_best_model.h5\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "        mode=\"min\", # Sauvegarder le modèle avec la perte minimale\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Early stopping\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=config.PATIENCE,\n",
    "        verbose=1, # Affichage d'un message\n",
    "        restore_best_weights=True # Restaurer les poids du meilleur modèle après l'arrêt\n",
    "    )\n",
    "\n",
    "    # 3. Entraîner le modèle\n",
    "    print(\"\\nDébut entraînement ss_cnn\\n\")\n",
    "    history = model.fit(\n",
    "        x=train_inputs,\n",
    "        y={\n",
    "            \"Sexe_output\": train_sexe_labels, \n",
    "            # \"Date_output\": train_date_labels,\n",
    "            },\n",
    "        epochs=config.EPOCHS,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        callbacks=[\n",
    "            checkpoint_callback, \n",
    "            early_stopping_callback,\n",
    "        ],\n",
    "        validation_data=(\n",
    "            val_inputs, \n",
    "            {\n",
    "                \"Sexe_output\": val_sexe_labels, \n",
    "                # \"Date_output\": val_date_labels,\n",
    "            }),\n",
    "    )\n",
    "    print(\"\\Fin entraînement ss_cnn\\n\")\n",
    "        \n",
    "    # Sauvegarder l'historique de l'entraînement en .json\n",
    "    with open(config.SS_CNN_RESULT_PATH + f\"{config.SS_CNN}_history.json\", \"w\") as json_file:\n",
    "        json.dump(history.history, json_file, indent=4)\n",
    "    # Sauvegarder l'historique de l'entraînement en .png\n",
    "    save_training_history(history_data=history.history, save_dir=config.SS_CNN_RESULT_PATH, base_filename=config.SS_CNN, single_figure=True)\n",
    "    save_training_history(history_data=history.history, save_dir=config.SS_CNN_RESULT_PATH, base_filename=config.SS_CNN, single_figure=False)\n",
    "\n",
    "\n",
    "    # Evaluation --------------------------------\n",
    "\n",
    "\n",
    "    # 1. Charger les données de tests\n",
    "    inputs_and_labels = data.main()\n",
    "\n",
    "    test_inputs = inputs_and_labels[\"test_inputs\"]\n",
    "    test_sexe_labels = inputs_and_labels[\"test_sexe_labels\"]\n",
    "    test_date_labels = inputs_and_labels[\"test_date_labels\"]\n",
    "\n",
    "    # Libérer la mémoire occupée par inputs_and_labels\n",
    "    del inputs_and_labels\n",
    "\n",
    "    # Évaluer le modèle sur les données de test avec le GPU\n",
    "    evaluation_results = model.evaluate(\n",
    "        x = test_inputs,\n",
    "        y = {\n",
    "            \"Sexe_output\": np.array(test_sexe_labels),\n",
    "            # \"Date_output\": np.array(test_date_labels),\n",
    "        },\n",
    "        return_dict=True\n",
    "    )\n",
    "        \n",
    "    print(\"\\nEvaluation...\\n\")\n",
    "    pprint.pp(evaluation_results)\n",
    "\n",
    "    # Sauvegarder les résultats de l'évaluation\n",
    "    with open(config.SS_CNN_RESULT_PATH + f\"{config.SS_CNN}_evaluation_results.json\", \"w\") as json_file:\n",
    "        json.dump(evaluation_results, json_file, indent=4)\n",
    "        \n",
    "    # Charger le modèle pré entraîné\n",
    "    # model = load_model(\n",
    "    #     filepath=config.SS_CNN_RESULT_PATH + f\"{config.SS_CNN}_best_model.h5\", \n",
    "    #     custom_objects=custom_objects_dict()\n",
    "    # )\n",
    "\n",
    "    print(\"\\nPrédictions...\\n\")\n",
    "    prediction_df = prediction(model=model, input_data=test_inputs, sexe_label=test_sexe_labels, date_label=None)\n",
    "\n",
    "    evaluate_model(\n",
    "        df=prediction_df, \n",
    "        confusion_matrix_output=config.SS_CNN_RESULT_PATH + f\"{config.SS_CNN}_confusion_matrix.png\", \n",
    "        roc_curve_output=config.SS_CNN_RESULT_PATH + f\"{config.SS_CNN}_roc_curve.png\"\n",
    "    )\n",
    "\n",
    "    prediction_df[\"interval\"] = prediction_df[\"true date\"].map(config.DATE_MAP)\n",
    "\n",
    "    save_hist_confusion_matrix(df=prediction_df, output_file=config.SS_CNN_RESULT_PATH + f\"{config.SS_CNN}_hist_confusion_matrix.png\")\n",
    "\n",
    "    save_accuracy_by_interval_and_gender(df=prediction_df, output_file=config.SS_CNN_RESULT_PATH + f\"{config.SS_CNN}_accuracy_by_interval_sexes.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
